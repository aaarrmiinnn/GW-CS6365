{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i_f5u2x9nn6I",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<left><img width=25% src=\"img/gw_monogram_2c.png\"></left>\n",
    "\n",
    "# Lecture 1: Advance Machine Learning\n",
    "\n",
    "### CS4907/CS6365 Machine Learning\n",
    "\n",
    "__Sardar Hamidian__<br>The George Washington Universiry\n",
    "\n",
    "__Armin Mehrabian__<br>The George Washington Universiry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Welcome to Advance Machine Learning!\n",
    "\n",
    "Machine learning is one of today's most exciting emerging technologies.\n",
    "\n",
    "In this course,\n",
    "* You will expand your machine learning knowledge.\n",
    "* You will learn how to ideate and execute as a machine learning expert.\n",
    "* You will learn how to apply machine learning to real-world problems (Search, Recommendation, NLP, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Welcome to Advance Machine Learning!\n",
    "\n",
    "* __Meeting time:__ Fridays 12:45pm - 15:15pm \n",
    "* __Instructors:__ \tSardar Hamidian, Armin Mehrabian  \n",
    "* __E-mails:__ \tsardar@gwu.edu, armin@gwu.edu\n",
    "* __Office hours:__ Online By appointment\n",
    "\n",
    "<center><img src=\"img/lec1-1.jpg\"/></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# About Us:\n",
    "\n",
    "- __Sardar Hamidian:__\n",
    "> - PhD in CS from GWU\n",
    "> - Senior Principal Machine Learning Researcher at Comcast AI\n",
    "\n",
    "- __Armin Mehrabian:__\n",
    "> - PhD in CompE from GWU\n",
    "> - Senior Principal Machine Learning Data Scientist at NASA Goddard Space Flight Center\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# About the class\n",
    "\n",
    "### Syllabus\n",
    "* Posted on Blackboard\n",
    "\n",
    "### Religious holidays\n",
    "* Tell us in advance when you will be off\n",
    "\n",
    "### Disability\n",
    "*  Please bring the written statement on how to accommodate your needs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Prerequisites: Is This Course For You?\n",
    "\n",
    "This course is aimed at a technical audience with prior ML experience. The main requirements are:\n",
    "\n",
    "* Passed the intoduction to machine learning course before\n",
    "\n",
    "If you have not, please reach out to us after the class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# About the class\n",
    "* Homework(35 percent of the final grade)\n",
    "* Final Project (35 percent of the final grade)\n",
    "* Quizes (30 percent of the final grade)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Project\n",
    "\n",
    "Course projects will be done individually in the following categories:\n",
    "* Application of machine learning on rael industry task\n",
    "* Algorithmic improvements into the representation, learning, or evaluation of machine learning models\n",
    "\n",
    "You are encouraged to choose your project, but we will make suggestions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Software You Will Use\n",
    "\n",
    "You will use Python and a wide range of machine learning, production, and graph-based tools, including:\n",
    "\n",
    "- **scikit-learn**: Implements most classical machine learning algorithms.\n",
    "- **tensorflow, pytorch**: Standard libraries for modern deep learning, including support for large-scale training and deployment.\n",
    "- **numpy, pandas**: Essential libraries for linear algebra and data processing, enabling you to implement algorithms from scratch.\n",
    "- **AWS Tools and Services**: For cloud-based storage, computation, and model deployment. Includes S3, EC2, SageMaker, and Lambda.\n",
    "- **Docker, Kubernetes**: For containerization and orchestration of models in a production environment, ensuring scalability and reproducibility.\n",
    "- **MLflow**: A platform to manage the ML lifecycle, including experimentation, reproducibility, and deployment.\n",
    "- **Hugging Face Transformers**: Tools and pre-trained models for building and fine-tuning large language models (LLMs) and other generative models.\n",
    "- **GPT-3, GPT-4 API**: For integrating advanced LLMs into your projects and exploring generative AI applications.\n",
    "- **LangChain**: Framework for developing applications powered by LLMs, with components for context management, memory, and advanced prompt engineering.\n",
    "- **Neo4**: Tools for building and querying knowledge graphs, enabling the integration of structured, semantic data into your models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Background For Today's session\n",
    "Recommendation systems play an important role in many e-commerce applications as well as search and ranking services. \n",
    "There are two main strategies to perform recommendations: `content and collaborative\n",
    "filtering`. In content filtering the user creates a profile based on its interest, while\n",
    "human experts create a profile for the product. An algorithm matches the two\n",
    "profiles and recommends the closest matches to the user. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Session 1: Introduction to Recommender Systems\n",
    "\n",
    "1. Introduction: Impact of recommender systems, the recommender problem\n",
    "2. The Netflix Prize\n",
    "3. Traditional approaches to recommendation\n",
    "    * Collaborative Filtering\n",
    "    * Content-based Recommendations\n",
    "4. Hybrid recommendations\n",
    "5. A Recsys Architecture Blueprint\n",
    "6. Takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The Recommender Problem!\n",
    "Traditional definition: Estimate a utility function that predicts how much a user will like an item.\n",
    "* Based on:\n",
    "    * Past behavior\n",
    "    * Relations to other users\n",
    "    * Item similarity\n",
    "    * Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Information Overload!\n",
    "<br>\n",
    "<center><img src=\"img/24data.webp\" style=\"width:70%; height:auto;\"/></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data never sleeps\n",
    "<br>\n",
    "<center><img src=\"img/domo9.png\" style=\"width:50%; height:auto;\"/></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Everything is Personalized\n",
    "<br>\n",
    "<center><img src=\"img/recapps.jpg\" style=\"width:70%; height:auto;\"/></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Recommendation as Data Mining\n",
    "\n",
    "Core of Recommendation Engine assimilated to a general data mining problem\n",
    "\n",
    "<center><img src=\"img/dmin.jpg\" style=\"width:50%; height:auto;\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Serendipity!\n",
    "* Unsought finding\n",
    "* Don't recommend items the user already knows or would have found anyway.\n",
    "* Expand the user's taste into neighboring areas by improving the obvious\n",
    "* Serendipity is connected to the explore/exploit tradeoff as well as to causality of recommendations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Collaborative Filtering (CF) Approach\n",
    "\n",
    "In collaborative filtering, the recommendations are based only on user past\n",
    "behavior from which the future behavior is derived. The advantage of this\n",
    "approach is that it requires no external information and is not domain specific.\n",
    "\n",
    "* Depends on the domain and particular problem\n",
    "* The best isolated approach\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<!-- <left><img width=25% src=\"img/gw_monogram_2c.png\"></left>\n",
    " -->\n",
    "<center><img src=\"img/netprize.webp\" style=\"width:50%; height:auto;\"/></center>\n",
    "\n",
    "\n",
    "# Part 2: The Netflix Prize \n",
    "\n",
    "* High-quality recommendations\n",
    "* Proxy question: Accuracy in predicted rating\n",
    "* Improve by 10% = $1 million!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Contest\n",
    "\n",
    "* Given:\n",
    "    * 100M ratings on 18K movies/500K users (1999-2005)\n",
    "* Predict:\n",
    "    * Next 2.8M ratings, 6 per user With 10% better RMSE than Netflix\n",
    "    \n",
    "<center><img src=\"img/mlen.jpg\" style=\"float: center; width: 20%; height: auto;\"/></center>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 2007 Progress Prize\n",
    "* Top 2 algorithms:\n",
    "    * SVD: Prize RMSE: 0.8914\n",
    "    * RBM: Prize RMSE: 0.8990\n",
    "\n",
    "* Linear blend Prize RMSE: 0.88\n",
    "* Used as part of Netflix’s rating prediction component\n",
    "* Limitations\n",
    "    * Designed for 100M ratings, not XB ratings\n",
    "    * Not adaptable as users add ratings\n",
    "    * Performance issues\n",
    "\n",
    "<center><img src=\"img/netflix.jpg\" style=\"width:50%; height:auto;\"/></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# SVD/MF\n",
    "<center><img src=\"img/MF.jpg\" style=\"width:50%; height:auto;\"/></center>\n",
    "<center><img src=\"img/SVD.jpg\" style=\"width:70%; height:auto;\"/></center>\n",
    "\n",
    "\n",
    "* X: m x n matrix (e.g., m users, n videos)\n",
    "* U: m x r matrix (m users, r factors)\n",
    "* S: r x r diagonal matrix (strength of each ‘factor’) (r: rank of the matrix)\n",
    "* V: r x n matrix (n videos, r factor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Singular Vectors (U):\n",
      "[[-7.88170109e-01  1.87057766e-16 -6.15457455e-01]\n",
      " [ 3.84473224e-01 -7.80868809e-01 -4.92365964e-01]\n",
      " [-4.80591530e-01 -6.24695048e-01  6.15457455e-01]]\n",
      "Singular Values (S):\n",
      "[1.62480768 1.        ]\n",
      "Right Singular Vectors (V^T):\n",
      "[[-0.78086881 -0.62469505]\n",
      " [ 0.62469505 -0.78086881]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import svd\n",
    "\n",
    "# Define the matrix A\n",
    "A = np.array([[1, -0.8],\n",
    "              [0, 1],\n",
    "              [1, 0]])\n",
    "\n",
    "# Perform Singular Value Decomposition\n",
    "U, S, VT = svd(A, full_matrices=True)\n",
    "\n",
    "# Print the results\n",
    "print(\"Left Singular Vectors (U):\")\n",
    "print(U)\n",
    "\n",
    "print(\"Singular Values (S):\")\n",
    "print(S)\n",
    "\n",
    "print(\"Right Singular Vectors (V^T):\")\n",
    "print(np.transpose(VT))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.62480768 0.        ]\n",
      " [0.         1.        ]\n",
      " [0.         0.        ]]\n",
      "[[ 1.00000000e+00 -8.00000000e-01]\n",
      " [ 8.93385967e-18  1.00000000e+00]\n",
      " [ 1.00000000e+00  1.23451001e-16]] \n",
      " [[ 1.  -0.8]\n",
      " [ 0.   1. ]\n",
      " [ 1.   0. ]]\n",
      "4.741952567914139e-16\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import multi_dot, norm\n",
    "\n",
    "# Create the smat matrix\n",
    "smat = np.zeros((3, 2))\n",
    "smat[:2, :2] = np.diag(S)\n",
    "print(smat)\n",
    "\n",
    "# Reconstruct the original matrix A using U, smat, and VT\n",
    "reconstructed_A = multi_dot([U, smat, VT])\n",
    "print(reconstructed_A, '\\n', A)\n",
    "\n",
    "# Calculate the norm of the difference between A and the reconstructed matrix\n",
    "difference_norm = norm(A - reconstructed_A)\n",
    "print(difference_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 3) (3,) (3, 3)\n",
      "[1.57539511e+00 5.63851375e-09 3.52439559e-09]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import svd\n",
    "\n",
    "# Define the matrix A\n",
    "A = np.array([[0.16492833, 0.61643322, 0.27304301],\n",
    "              [0.23179766, 0.86636283, 0.38374687],\n",
    "              [0.03342004, 0.12491015, 0.05532772],\n",
    "              [0.22841804, 0.85373123, 0.37815182],\n",
    "              [0.07690245, 0.28742925, 0.12731395]])\n",
    "\n",
    "# Perform Singular Value Decomposition\n",
    "U, S, VT = svd(A, full_matrices=False)\n",
    "\n",
    "# Print the shapes of U, S, and VT\n",
    "print(U.shape, S.shape, VT.shape)\n",
    "\n",
    "# Print the singular values\n",
    "print(S)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.         -0.8       ]\n",
      " [-0.48780488  0.3902439 ]\n",
      " [ 0.6097561  -0.48780488]]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Define the rank for approximation\n",
    "rank = 1\n",
    "\n",
    "# Extract the first 'rank' columns and rows from U, S, and VT\n",
    "U_sub = U[:, :rank]\n",
    "VT_sub = VT[:rank, :]\n",
    "S_sub = np.diag(S[:rank])\n",
    "\n",
    "# Compute the low-rank approximation of A\n",
    "A_low_rank = np.dot(np.dot(U_sub, S_sub), VT_sub)\n",
    "\n",
    "# Print the low-rank approximation of A\n",
    "print(A_low_rank)\n",
    "\n",
    "# Calculate and print the norm of the difference between the original and low-rank approximation\n",
    "from numpy.linalg import norm\n",
    "print(norm(A - A_low_rank))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Simon Funk’s SVD\n",
    "* One of the most interesting\n",
    "findings during the Netflix Prize\n",
    "came out of a blog post\n",
    "* Incremental, iterative, using gradient descent to perform SVD iteratively. Instead of computing the full SVD\n",
    "* Regularization:regularization term is introduced to prevent overfitting.\n",
    "* Efficiency: computationally efficient and effective in prediction accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# SVD for Rating Prediction\n",
    "\n",
    "- **User factor vectors**: $ p_u \\in \\mathbb{R}^f$ and item-factor vector $ q_v \\in \\mathbb{R}^f $\n",
    "\n",
    "- **Baseline (bias)**: $ b_{uv} = \\mu + b_u + b_v $ (user & item deviation from average)\n",
    "\n",
    "- **Predict rating as**: $ r'_{uv} = b_{uv} + p_u^T q_v $\n",
    "\n",
    "- **Asymmetric SVD (Koren et. Al) asymmetric variation w. implicit feedback**\n",
    "\n",
    "- **Where** $\n",
    "r'_{uv} = b_{uv} + q_v^T \\left( \\left| R(u) \\right|^{-\\frac{1}{2}} \\sum_{j \\in R(u)} (r_{uj} - b_{uj}) x_j + \\left| N(u) \\right|^{-\\frac{1}{2}} \\sum_{j \\in N(u)} y_j \\right)\n",
    "$\n",
    "\n",
    "    * $q_v, x_v, y_v \\in \\mathbb{R}^f$ are three item factor vectors\n",
    "    * Users are not parametrized, but rather represented by:\n",
    "        * R(u): items rated by user u\n",
    "        * N(u): items for which the user has given implicit preference (e.g. rated vs. not rated)\n",
    "        \n",
    "\n",
    "\n",
    "<!-- - $q_v$ : For predicting explicit ratings.\n",
    "- $x_v$: Relates to items explicitly rated by the user.\n",
    "- $y_v$: Captures implicit feedback from items the user interacted with but didn't rate. -->\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# Practical Applications of SVD: \n",
    "\n",
    "* Dimensionality Reduction: SVD is often used in Principal Component Analysis (PCA) to reduce the number of features in a dataset while preserving as much variability as possible.\n",
    "* Noise Reduction: By truncating smaller singular values, you can remove noise from data while keeping the essential structure.\n",
    "* Collaborative Filtering: SVD is used in recommendation systems (like the Netflix Prize) to identify patterns in user-item matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Matrix (A):\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "\n",
      "Reconstructed Matrix (A_reconstructed):\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]\n",
      " [7. 8. 9.]]\n",
      "\n",
      "Are they equal?  True [1.68481034e+01 1.06836951e+00 3.33475287e-16] [[-0.47967118 -0.57236779 -0.66506441]\n",
      " [-0.77669099 -0.07568647  0.62531805]\n",
      " [-0.40824829  0.81649658 -0.40824829]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Original Matrix\n",
    "A = np.array([[1, 2, 3],\n",
    "              [4, 5, 6],\n",
    "              [7, 8, 9]])\n",
    "\n",
    "# Perform SVD\n",
    "U, Sigma, VT = np.linalg.svd(A)\n",
    "\n",
    "# Reconstruct the original matrix using U, Sigma, and VT\n",
    "Sigma_matrix = np.zeros((U.shape[0], VT.shape[0]))\n",
    "np.fill_diagonal(Sigma_matrix, Sigma)\n",
    "A_reconstructed = np.dot(U, np.dot(Sigma_matrix, VT))\n",
    "\n",
    "# Output the results\n",
    "print(\"Original Matrix (A):\")\n",
    "print(A)\n",
    "\n",
    "print(\"\\nReconstructed Matrix (A_reconstructed):\")\n",
    "print(A_reconstructed)\n",
    "\n",
    "# Check if the original and reconstructed matrices are close\n",
    "print(\"\\nAre they equal? \", np.allclose(A, A_reconstructed), Sigma, VT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Matrix (A):\n",
      "[[ 1  2  3]\n",
      " [ 4  5  6]\n",
      " [ 7  8  9]\n",
      " [10 11 12]]\n",
      "\n",
      "Reconstructed Matrix with Truncated SVD (A_reconstructed_truncated):\n",
      "[[ 1.80979033  2.06082192  2.31185351]\n",
      " [ 4.41855027  5.03143657  5.64432287]\n",
      " [ 7.02731022  8.00205122  8.97679223]\n",
      " [ 9.63607016 10.97266587 12.30926159]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Original Matrix\n",
    "A = np.array([[1, 2, 3],\n",
    "              [4, 5, 6],\n",
    "              [7, 8, 9],\n",
    "              [10, 11, 12]])\n",
    "\n",
    "# Perform SVD\n",
    "U, Sigma, VT = np.linalg.svd(A)\n",
    "\n",
    "# Reconstruct the matrix using only the first singular value this is called low rank approaximation\n",
    "# Why do even wanna do this?\n",
    "\n",
    "k = 1  # Only use the first singular value\n",
    "Sigma_truncated = np.zeros((U.shape[0], VT.shape[0]))\n",
    "np.fill_diagonal(Sigma_truncated[:k, :k], Sigma[:k])\n",
    "A_reconstructed_truncated = np.dot(U, np.dot(Sigma_truncated, VT))\n",
    "\n",
    "# Output the results\n",
    "print(\"Original Matrix (A):\")\n",
    "print(A)\n",
    "\n",
    "print(\"\\nReconstructed Matrix with Truncated SVD (A_reconstructed_truncated):\")\n",
    "print(A_reconstructed_truncated)\n",
    "\n",
    "# Visualize the original and reconstructed matrices\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Original Matrix A\")\n",
    "plt.imshow(A, aspect='auto', cmap='viridis')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Truncated SVD Reconstruction\")\n",
    "plt.imshow(A_reconstructed_truncated, aspect='auto', cmap='viridis')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Restricted Boltzmann Machines\n",
    "\n",
    "* Each unit is a state that can be active or not active\n",
    "* Each input to a unit is associated with a weight\n",
    "* Transfer function $Σ$ calculates a score for every unit based on the weighted sum of inputs\n",
    "* Score is passed to the activation function $Φ$ that calculates the probability of the unit being active\n",
    "* Restrict the connectivity to make learning easier\n",
    "    * Only one layer of hidden units\n",
    "    * No connections between hidden units\n",
    "    * Hidden units are independent given visible states\n",
    "   \n",
    "<center>\n",
    "    <img src=\"img/boltzman.jpg\" style=\"width: 500px; height: auto; margin-left: 100px;\"/>\n",
    "    <br/>\n",
    "    <a href=\"https://medium.com/machine-learning-researcher/boltzmann-machine-c2ce76d94da5\" target=\"_blank\">\n",
    "        If you want to know more\n",
    "    </a>\n",
    "</center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# RBM For Recommendation\n",
    "\n",
    "* Each visible unit = an item\n",
    "* Num. of hidden units $a$ is parameter\n",
    "* In training phase, for each user:\n",
    "    * If user rated item, $v_i$ is activated\n",
    "    * Activation states of $v_i$ = inputs to $h_j$\n",
    "    * Based on activation, $h_j$ is computed\n",
    "    * Activation state of $h_j$ becomes input to $v_i$\n",
    "    * Activation state of $v_i$ is recalculated\n",
    "    * Difference between current and past activation state for $v_i$ used to update\n",
    "* weights $w_{ij}$ and thresholds\n",
    "* In prediction phase:\n",
    "    * For the items of the user the $v_i$ are activated\n",
    "    * Based on this the state of the $h_j$ is computed\n",
    "    * The activation of $h_j$ is used as input to recompute the state of $v_i$\n",
    "    * Activation probabilities are used to recommend items\n",
    "\n",
    "<div style=\"text-align: center; margin-top: 20px;\">\n",
    "    <img src=\"img/rbfrec1.jpg\" style=\"width: 400px; height: auto; display: block; margin: 10px auto;\"/>\n",
    "    <img src=\"img/rbfrec2.jpg\" style=\"width: 300px; height: auto; display: block; margin: 10px auto;\"/>\n",
    "    <img src=\"img/rbfrec3.jpg\" style=\"width: 300px; height: auto; display: block; margin: 10px auto;\"/>\n",
    "    <br/>\n",
    "    <a href=\"https://www.cs.toronto.edu/~rsalakhu/papers/rbmcf.pdf\" target=\"_blank\" style=\"display: block; margin: 20px auto;\">\n",
    "        Link to the Paper\n",
    "    </a>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recommender Systems\n",
    "* Initial production model at Netflix included a linear ensemble of both SVD++ and RBMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What about the final prize ensembles?\n",
    "Final prize included 104 models ensembled through a single-layer ANN\n",
    "* Offline studies showed they were too computationally intensive to scale\n",
    "* Expected improvement not worth engineering effort\n",
    "* Plus…. Focus had already shifted to other issues that had more impact than rating prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Part 3:  Traditional Approaches to Recommender Systems\n",
    "<br>\n",
    "<center><img src=\"img/cf.jpg\" style=\"display: block; width: 80%; height: auto; margin: 0 auto;\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The CF Ingredient\n",
    "\n",
    "\n",
    "* List of m Users and a list of n Items\n",
    "* Each user has a list of items with associated opinion\n",
    "    * Explicit preference - a rating score\n",
    "    * And/or Implicit preference – purchased record or listened to track\n",
    "* Active user for whom the CF prediction task is performed\n",
    "* Metric for measuring similarity between users\n",
    "* Method for selecting a subset of neighbors\n",
    "* Method for predicting a rating/preference for items with unknown preference\n",
    "by the active user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Personalized vs Non-Personalized CF\n",
    "\n",
    "* CF recommendations are personalized: prediction based\n",
    "only on similar users\n",
    "* Non-personalized collaborative-based recommendation:\n",
    "average the recommendations of ALL the users\n",
    "* How would the two approaches compare?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Personalized vs. Not Personalized\n",
    "* Netflix Prize: it is very simple to produce “reasonable” recommendations and extremely difficult to improve them to become “great”\n",
    "* But there is a huge difference in business value between reasonable and great\n",
    "\n",
    "<div style=\"text-align: center; margin-top: 20px;\">\n",
    "    <img src=\"img/popcf.jpg\" style=\"width:1000px; height: auto; display: block; margin: 10px auto;\"/>\n",
    "    <br/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# User-based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# UB Collaborative Filtering\n",
    "\n",
    "The basic steps:\n",
    "\n",
    "1. **Identify set of ratings/preferences for the <span style=\"color:red\">target/active user</span>**\n",
    "\n",
    "2. **Identify set of users most similar to the target/active user according to a similarity function (<span style=\"color:red\">neighborhood formation</span>)**\n",
    "\n",
    "3. **Identify the products these similar users liked**\n",
    "\n",
    "4. **<span style=\"color:red\">Generate a prediction</span> - rating that would be given by the target user to the product - for each one of these products**\n",
    "\n",
    "5. **Based on this predicted rating, recommend a set of top N products**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# UB Collaborative Filtering\n",
    "\n",
    "\n",
    "* A collection of users $u_i$, $i = 1, \\ldots, n$ and a collection of products $p_j$, $j = 1, \\ldots, m$.\n",
    "* An $n \\times m$ matrix of ratings $v_{ij}$, with $v_{ij} = ?$ if user $i$ did not rate product $j$.\n",
    "* Prediction for user $i$ and product $j$ is computed as:\n",
    "\n",
    "$ v_{ij}^* = K \\sum_{v_{kj} \\neq ?} u_{jk} v_{kj} $\n",
    "$\\quad$ or $\\quad$ \n",
    "$ v_{ij}^* = v_i + K \\sum_{v_{kj} \\neq ?} u_{jk} (v_{kj} - v_k) $\n",
    "\n",
    "* Similarity can be computed by Pearson correlation, cosine similarity…\n",
    "\n",
    "$ u_{ik} = \\frac{\\sum_j (v_{ij} - v_i)(v_{kj} - v_k)}{\\sqrt{\\sum_j (v_{ij} - v_i)^2 \\sum_j (v_{kj} - v_k)^2}} $\n",
    "$\\quad$ or $\\quad$ \n",
    "$ \\cos(u_i, u_j) = \\frac{\\sum_{k=1}^m v_{ik} v_{jk}}{\\sqrt{\\sum_{k=1}^m v_{ik}^2 \\sum_{k=1}^m v_{jk}^2}} $\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simple Example of User-Based Collaborative Filtering\n",
    "\n",
    "### Scenario\n",
    "Imagine a small movie recommendation system with the following setup:\n",
    "\n",
    "- **Users**: Alice, Bob, and Carol\n",
    "- **Movies**: \"Matrix,\" \"Inception,\" \"Titanic,\" \"Avatar\"\n",
    "- **Ratings**: Each user has rated some of these movies.\n",
    "\n",
    "### Step 1: Rating Matrix\n",
    "Let's start with the following rating matrix:\n",
    "\n",
    "|         | Matrix | Inception | Titanic | Avatar |\n",
    "|---------|--------|-----------|---------|--------|\n",
    "| **Alice** |   5    |     4     |    ?    |   3    |\n",
    "| **Bob**   |   4    |     ?     |    3    |   5    |\n",
    "| **Carol** |   ?    |     5     |    4    |   4    |\n",
    "\n",
    "*Note*: \"?\" denotes that the user hasn't rated that movie.\n",
    "\n",
    "### Step 2: Compute User Similarities\n",
    "\n",
    "We will compute the similarity between Alice and the other users (Bob and Carol) using **Pearson Correlation**.\n",
    "\n",
    "#### Pearson Correlation Formula\n",
    "The Pearson Correlation between two users $u$ and $v$ is defined as:\n",
    "\n",
    "$$\n",
    "\\text{Sim}(u, v) = \\frac{\\sum_{i \\in I_{uv}} (r_{u,i} - \\bar{r}_u)(r_{v,i} - \\bar{r}_v)}{\\sqrt{\\sum_{i \\in I_{uv}} (r_{u,i} - \\bar{r}_u)^2} \\cdot \\sqrt{\\sum_{i \\in I_{uv}} (r_{v,i} - \\bar{r}_v)^2}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $I_{uv}$ is the set of items rated by both users $u$ and $v$.\n",
    "- $r_{u,i}$ is the rating given by user $u$ to item $i$.\n",
    "- $\\bar{r}_u$ is the average rating of user $u$.\n",
    "\n",
    "#### Similarity Calculations\n",
    "\n",
    "1. **Alice and Bob**:\n",
    "   - **Common movies**: Matrix, Avatar\n",
    "   - **Alice’s ratings**: Matrix (5), Avatar (3)\n",
    "   - **Bob’s ratings**: Matrix (4), Avatar (5)\n",
    "   - **Alice's average rating**: $\\bar{r}_{\\text{Alice}} = \\frac{5 + 4 + 3}{3} = 4$\n",
    "   - **Bob's average rating**: $\\bar{r}_{\\text{Bob}} = \\frac{4 + 3 + 5}{3} = 4$\n",
    "   - **Adjusted ratings**:\n",
    "     - Alice: Matrix (5 - 4 = 1), Avatar (3 - 4 = -1)\n",
    "     - Bob: Matrix (4 - 4 = 0), Avatar (5 - 4 = 1)\n",
    "   - **Similarity**:\n",
    "   $$\n",
    "   \\text{Sim}(\\text{Alice}, \\text{Bob}) = \\frac{(1 \\times 0) + (-1 \\times 1)}{\\sqrt{1^2 + (-1)^2} \\cdot \\sqrt{0^2 + 1^2}} = -0.71\n",
    "   $$\n",
    "\n",
    "2. **Alice and Carol**:\n",
    "   - **Common movies**: Inception, Avatar\n",
    "   - **Alice’s ratings**: Inception (4), Avatar (3)\n",
    "   - **Carol’s ratings**: Inception (5), Avatar (4)\n",
    "   - **Carol's average rating**: $\\bar{r}_{\\text{Carol}} = \\frac{5 + 4 + 4}{3} = 4.33$\n",
    "   - **Adjusted ratings**:\n",
    "     - Alice: Inception (4 - 4 = 0), Avatar (3 - 4 = -1)\n",
    "     - Carol: Inception (5 - 4.33 \\approx 0.67), Avatar (4 - 4.33 \\approx -0.33)\n",
    "   - **Similarity**:\n",
    "   $$\n",
    "   \\text{Sim}(\\text{Alice}, \\text{Carol}) = \\frac{(0 \\times 0.67) + (-1 \\times -0.33)}{\\sqrt{0^2 + (-1)^2} \\cdot \\sqrt{0.67^2 + (-0.33)^2}} \\approx 0.23\n",
    "   $$\n",
    "\n",
    "### Step 3: Predict Rating\n",
    "Now, let's predict Alice’s rating for \"Titanic\" based on the ratings provided by Bob and Carol.\n",
    "\n",
    "**Alice's Predicted Rating for Titanic**:\n",
    "\n",
    "$$\n",
    "\\text{Predicted Rating for Titanic} = \\bar{r}_{\\text{Alice}} + \\frac{\\text{Sim}(\\text{Alice}, \\text{Bob}) \\times (3 - 4) + \\text{Sim}(\\text{Alice}, \\text{Carol}) \\times (4 - 4.33)}{|\\text{Sim}(\\text{Alice}, \\text{Bob})| + |\\text{Sim}(\\text{Alice}, \\text{Carol})|}\n",
    "$$\n",
    "\n",
    "$$\n",
    "= 4 + \\frac{-0.71 \\times -1 + 0.23 \\times -0.33}{|-0.71| + |0.23|} \\approx 4.42\n",
    "$$\n",
    "\n",
    "### Summary\n",
    "In this example, **User-Based Collaborative Filtering** predicts how Alice might rate \"Titanic\" by looking at how similar her tastes are to those of other users (Bob and Carol). It then combines their ratings for \"Titanic,\" weighted by their similarity to Alice, to predict her rating. This approach leverages the idea that users with similar preferences are likely to agree on future ratings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Item-based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Item-based Collaborative Filtering\n",
    "* Look into the items the target user has rated\n",
    "* Compute how similar they are to the target item\n",
    "    * Similarity only using past ratings from other users!\n",
    "* Select k most similar items.\n",
    "* Compute Prediction by taking weighted average on the\n",
    "target user’s ratings on the most similar items.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Item Similarity Computation\n",
    "\n",
    "- Similarity: find users who have rated items and apply a similarity function to their ratings.\n",
    "\n",
    "- **Cosine-based Similarity** (difference in rating scale between users is not taken into account):\n",
    "\n",
    "$ S(i,j) = \\cos(\\bar{i}, \\bar{j}) = \\frac{\\bar{i} \\cdot \\bar{j}}{\\|\\bar{i}\\|_2 * \\|\\bar{j}\\|_2} $\n",
    "\n",
    "- **Adjusted Cosine Similarity** (takes care of difference in rating scale):\n",
    "\n",
    "$ S(i,j) = \\frac{\\sum_{u \\in U} (R_{u,i} - \\bar{R_u})(R_{u,j} - \\bar{R_u})}{\\sqrt{\\sum_{u \\in U} (R_{u,i} - \\bar{R_u})^2 \\sum_{u \\in U} (R_{u,j} - \\bar{R_u})^2}} $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Example of Item-Based Collaborative Filtering\n",
    "\n",
    "### Scenario\n",
    "Imagine a small movie recommendation system with the following setup:\n",
    "\n",
    "- **Users**: Alice, Bob, and Carol\n",
    "- **Movies**: \"Matrix,\" \"Inception,\" \"Titanic,\" \"Avatar\"\n",
    "- **Ratings**: Each user has rated some of these movies.\n",
    "\n",
    "### Step 1: Rating Matrix\n",
    "Let's start with the following rating matrix:\n",
    "\n",
    "|         | Matrix | Inception | Titanic | Avatar |\n",
    "|---------|--------|-----------|---------|--------|\n",
    "| **Alice** |   5    |     4     |    ?    |   3    |\n",
    "| **Bob**   |   4    |     ?     |    3    |   5    |\n",
    "| **Carol** |   ?    |     5     |    4    |   4    |\n",
    "\n",
    "*Note*: \"?\" denotes that the user hasn't rated that movie.\n",
    "\n",
    "### Step 2: Compute Item Similarities\n",
    "Using **Adjusted Cosine Similarity**, we'll compute how similar \"Titanic\" is to the other movies based on the ratings provided by Alice, Bob, and Carol.\n",
    "\n",
    "#### Similarity Calculations\n",
    "\n",
    "- **Titanic and Matrix**:\n",
    "  - **Common users**: Bob\n",
    "  - **Bob’s ratings**: Matrix (4), Titanic (3)\n",
    "  - Since only Bob has rated both, the similarity score is based on just his ratings.\n",
    "\n",
    "- **Titanic and Inception**:\n",
    "  - **Common users**: Carol\n",
    "  - **Carol’s ratings**: Inception (5), Titanic (4)\n",
    "  - Similarity score is based on Carol’s ratings.\n",
    "\n",
    "- **Titanic and Avatar**:\n",
    "  - **Common users**: Bob, Carol\n",
    "  - **Bob’s ratings**: Titanic (3), Avatar (5)\n",
    "  - **Carol’s ratings**: Titanic (4), Avatar (4)\n",
    "  - The similarity score is calculated considering both Bob’s and Carol’s ratings.\n",
    "\n",
    "Assuming the calculated similarities (normalized and adjusted for user biases) are as follows:\n",
    "\n",
    "- $Sim(\\text{Titanic}, \\text{Matrix}) = 0.7$\n",
    "- $Sim(\\text{Titanic}, \\text{Inception}) = 0.9$\n",
    "- $Sim(\\text{Titanic}, \\text{Avatar}) = 0.8$\n",
    "\n",
    "### Step 3: Predict Rating\n",
    "Now, let's predict Alice’s rating for \"Titanic\" based on the movies she has rated:\n",
    "\n",
    "**Alice's Rating for Titanic**:\n",
    "\n",
    "$\n",
    "\\text{Predicted Rating for Titanic} = \\frac{0.7 \\times 5 + 0.9 \\times 4 + 0.8 \\times 3}{0.7 + 0.9 + 0.8} = \\frac{3.5 + 3.6 + 2.4}{2.4} \\approx 4.25\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Memory based CF: Pros/Cons\n",
    "\n",
    "- Requires **_minimal knowledge_** engineering efforts\n",
    "- Users and products are symbols without any internal structure or characteristics\n",
    "- Produces good-enough results in most cases\n",
    "\n",
    "**Challenges:**\n",
    "\n",
    "- **_Sparsity_** – evaluation of large itemsets where user/item interactions are under 1%.\n",
    "- **_Scalability_** - Nearest neighbor requires computation that grows with both the number of users and the number of items.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The Sparsity Problem\n",
    "\n",
    "- Typically: large product sets, user ratings for a small percentage of them (e.g., Amazon: millions of books and a user may have bought hundreds of books)\n",
    "  \n",
    "- If you represent the Netflix Prize rating data in a User/Movie matrix, you get…\n",
    "  - 500,000 x 17,000 = 8.5 B positions\n",
    "  - Out of which only 100M are non-zero\n",
    "  \n",
    "- Number of users was ~ 0.1 x size of the catalog\n",
    "\n",
    "<div style=\"text-align: center; margin-top: 20px;\">\n",
    "    <img src=\"img/sparse.jpg\" style=\"width: 400px; height: auto; display: block; margin: 10px auto;\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Model Based CF Algorithms\n",
    "\n",
    "- **Memory based**\n",
    "  - Use the entire user-item database to generate a prediction.\n",
    "  - Usage of statistical techniques to find the neighbors – e.g. nearest-neighbor.\n",
    "\n",
    "- **Model-based**\n",
    "  - First develop a model\n",
    "  - Type of model:\n",
    "    - Probabilistic (e.g., Bayesian Network)\n",
    "    - Clustering\n",
    "    - Rule-based approaches (e.g., Association Rules)\n",
    "    - Classification\n",
    "    - Regression\n",
    "    - LDA\n",
    "    - <span style=\"color:red\">Matrix Factorization (e.g., SVD)</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cluster\n",
    "* Goal: cluster users and compute per-cluster “typical”\n",
    "preferences\n",
    "* Users receive recommendations computed at the\n",
    "cluster level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Locality-sensitive Hashing (LSH)\n",
    "\n",
    "- Method for grouping similar items in highly dimensional spaces\n",
    "\n",
    "- Find a hashing function s.t. similar items are grouped in the same buckets\n",
    "\n",
    "- Main application is Nearest-neighbors\n",
    "  - Hashing function is found iteratively by concatenating random hashing functions\n",
    "  - Addresses one of NN main concerns: performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Other “interesting” clustering techniques\n",
    "\n",
    "- k-means and all its variations\n",
    "- Affinity Propagation\n",
    "- Spectral Clustering\n",
    "- Non-parametric Bayesian Clustering (e.g. HDPs)\n",
    "\n",
    "<!-- k-means and its variations:\n",
    "\n",
    "A widely used algorithm that partitions data into k clusters by minimizing within-cluster variance. Variations include k-medoids, which uses medoids instead of centroids, and spherical k-means, suitable for text data.\n",
    "Affinity Propagation:\n",
    "\n",
    "An algorithm that identifies exemplars among data points and forms clusters based on these exemplars, without needing to specify the number of clusters in advance.\n",
    "Spectral Clustering:\n",
    "\n",
    "A technique that uses the eigenvalues of a similarity matrix to reduce dimensionality before applying clustering, often producing better results on complex datasets.\n",
    "Non-parametric Bayesian Clustering (e.g., HDPs):\n",
    "\n",
    "Hierarchical Dirichlet Processes (HDPs) allow for an unknown number of clusters by using a non-parametric Bayesian approach, making them flexible for varying data sizes and structures -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Association rules\n",
    "\n",
    "- Past purchases are interpreted as transactions of “associated” items\n",
    "- If a visitor has some interest in Book 5, she will be recommended to buy Book 3 as well\n",
    "- Recommendations are constrained to some minimum levels of confidence\n",
    "- Fast to implement and execute (e.g., A Priori algorithm)\n",
    "\n",
    "<div style=\"text-align: center; margin-top: 20px;\">\n",
    "    <img src=\"img/alsobougth.jpg\" style=\"width: 700px; height: auto; display: block; margin: 10px auto;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<!-- <left><img width=25% src=\"img/gw_monogram_2c.png\"></left>-->\n",
    "<center><img src=\"img/classifier.jpg\" style=\"width:30%; height:auto;\"/></center>\n",
    "\n",
    "\n",
    "# Classifiers\n",
    "\n",
    "* Classifiers are general computational models trained using\n",
    "positive and negative examples\n",
    "* They may take in inputs:\n",
    "    * Vector of item features (action / adventure, Bruce Willis)\n",
    "    * Preferences of customers (like action / adventure)\n",
    "    * Relations among item\n",
    "* E.g. Logistic Regression, Bayesian Networks, Support Vector Machines, Decision Trees, etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Classifiers\n",
    "* Classifiers can be used in CF and CB Recommenders\n",
    "    * Pros:\n",
    "        * Versatile\n",
    "        * Can be combined with other methods to improve accuracy of recommendations\n",
    "    * Cons:\n",
    "        * Need a relevant training set\n",
    "        * May overfit (Regularization)\n",
    "    * E.g. Logistic Regression, Bayesian Networks, Support Vector Machines, Decision Trees, etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Matrix Factorization\n",
    "\n",
    "- *Since the Netflix Prize, MF has been the preferred approach to model-based collaborative filtering (and recommendation as a whole).*\n",
    "  \n",
    "- *Only recently (and arguably) challenged by Deep Learning*\n",
    "\n",
    "- *We already talked about SVD, a form of Matrix Factorization in the context of the Netflix Prize*\n",
    "\n",
    "- *SVD was designed at that time to operate on discrete numerical ratings, but has been extended very effectively since to other cases*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Matrix Factorization\n",
    "\n",
    "- **MF can be interpreted as**\n",
    "  - Unsupervised:\n",
    "    - Dimensionality Reduction similar to Principal Component Analysis (PCA)\n",
    "    - Clustering (e.g. NMF)\n",
    "  - Supervised:\n",
    "    - Labeled targets ~ regression\n",
    "\n",
    "- **Very useful variations of MF**\n",
    "  - Bayesian Personalized Ranking (BPR), Alternating Least Squares (ALS), Extension of Singular Value Decomposition (SVD++)\n",
    "  - Tensor Factorization, Factorization Machines\n",
    "  <center><img src=\"img/mfform.jpg\" style=\"width:50%; height:auto;\"/></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Alternating Least Squares\n",
    "* ALS is an optimized version of matrix\n",
    "factorization that uses conjugate\n",
    "gradient descent to solve for implicit\n",
    "datasets where there is a more dense\n",
    "matrix\n",
    "* It is considered the SOTA matrix\n",
    "factorization approach\n",
    "<center><img src=\"img/ALS1.jpg\" style=\"width:40%; height:auto;\"/></center>\n",
    "<br>\n",
    "<center><img src=\"img/ALS2.jpg\" style=\"width:40%; height:auto;\"/></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Python implicit \n",
    "Simple yet efficient python library that implements collaborative filtering approaches for implicit datasets\n",
    "* Item-based nearest neighbor models\n",
    "* ALS\n",
    "* BPR (Bayesian personalized Ranking)\n",
    "\n",
    "<center><img src=\"img/implicit.jpg\" style=\"width:30%; height:auto;\"/></center>\n",
    "If you're interested in implementing these techniques, you can explore the <a href=\"https://github.com/benfred/implicit\">Implicit library on GitHub</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Limitations of Collaborative Filtering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Limitations of Collaborative Filtering\n",
    "* Cold Start: There needs to be enough other users already in the system to find a match. New items need to get enough ratings.\n",
    "* Popularity Bias: Hard to recommend items to someone with unique tastes.\n",
    "* Tends to recommend popular items (items from the tail do not get so much data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 3.2. Content-based Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Content-Based Recommendation\n",
    "* Recommendations based on content of items rather than on other users’ opinions/interactions\n",
    "* Goal: recommend items similar to those the user liked\n",
    "* Common for recommending text-based products (web pages, usenet news messages, )\n",
    "* Items to recommend are “described” by their associated features (e.g. keywords)\n",
    "* User Model structured in a “similar” way as the content: features/keywords more likely to occur in the preferred documents (lazy approach)\n",
    "* The user model can be a classifier based on whatever technique (Neural Networks...)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pros/cons of CB Approach\n",
    "* Pros\n",
    "    * No need for data on other users: No cold-start or sparsity\n",
    "    * Able to recommend to users with unique tastes.\n",
    "    * Able to recommend new and unpopular items\n",
    "    * Can provide explanations by listing content-features\n",
    "* Cons\n",
    "    * Requires content that can be encoded as meaningful features (difficult in some domains/catalogs)\n",
    "    * Users represented as learnable function of content features.\n",
    "    * Difficult to implement exploration\n",
    "    * Easy to overfit (e.g. for a user with few data points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A word of caution\n",
    "<center><img src=\"img/woc.jpg\" style=\"width:60%; height:auto;\"/></center>\n",
    "\n",
    "https://sci-hub.se/10.1145/1639714.1639731"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep Learning and CB Recommendations \n",
    "* Machine learning analysis of “content” has been revolutionized by Deep Learning\n",
    "    * Many approaches to understanding images, text, or other kinds of content through Deep Learning\n",
    "    * Among them, embeddings are a great way to represent content (and users)\n",
    "* We will continue talking about Deep Learning solutions in Sessions 2 and beyond\n",
    "<center><img src=\"img/deepcf.jpg\" style=\"width:70%; height:auto;\"/></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Part 4. Hybrid recommendations\n",
    "<center><img src=\"img/hybrid.webp\" style=\"width:30%; height:auto;\"/></center>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Comparison of methods (FAB system)\n",
    "\n",
    "* Content–based recommendation with Bayesian classifier\n",
    "* Basic collaborative filtering using Pearson correlation\n",
    "* Collaboration via content uses the content-based user profiles\n",
    "<center><img src=\"img/FAB.jpg\" style=\"width:40%; height:auto;\"/></center>\n",
    "* Averaged on 44 users\n",
    "* Precision computed in top 3 recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hybridization Methods for Recommender Systems\n",
    "\n",
    "| **Hybridization Method**  | **Description** |\n",
    "|---------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Weighted**              | Outputs from several techniques (in the form of scores or votes) are combined with different degrees of importance to offer final recommendations.                               |\n",
    "| **Switching**             | Depending on the situation, the system changes from one technique to another.                                                                                                   |\n",
    "| **Mixed**                 | Recommendations from several techniques are presented at the same time.                                                                                                        |\n",
    "| **Feature combination**   | Features from different recommendation sources are combined as input to a single technique.                                                                                    |\n",
    "| **Cascade**               | The output from one technique is used as input to another that refines the result.                                                                                              |\n",
    "| **Feature augmentation**  | The output from one technique is used as input features to another.                                                                                                            |\n",
    "| **Meta-level**            | The model learned by one recommender is used as input to another.                                                                                                              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Everything is an ensemble\n",
    "\n",
    "- **Netflix Prize was won by an ensemble**\n",
    "  - Initially, Bellkor was using GDBTs\n",
    "  - BigChaos introduced ANN-based ensemble\n",
    "\n",
    "- **Most practical applications of ML run an ensemble**\n",
    "  - Why wouldn’t you?\n",
    "  - At least as good as the best of your methods\n",
    "  - Can combine different approaches (e.g., CF and content-based)\n",
    "  - Can use different models at the ensemble layer: LR, GDBTs, RFs, ANNs...\n",
    "\n",
    "<center><img src=\"img/ens1.jpg\" style=\"width:30%; height:auto;\"/></center>\n",
    "<center><img src=\"img/ens2.jpg\" style=\"width:30%; height:auto;\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Ensembles & Feature Engineering\n",
    "<center><img src=\"img/dwide.jpg\" style=\"width:90%; height:auto;\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 5. A Recsys Architecture Blueprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A Recsys Architecture Blueprint\n",
    "<center><img src=\"img/recsys1.jpg\" style=\"width:50%; height:auto;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A Recsys Other Blueprint\n",
    "<center><img src=\"img/recsys21.jpg\" style=\"width:50%; height:auto;\"/></center>\n",
    "<center><img src=\"img/recsys22.jpg\" style=\"width:70%; height:auto;\"/></center>\n",
    "https://fennel.ai/blog/real-world-recommendation-system/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Other Blueprint\n",
    "\n",
    "<center><img src=\"img/recsys4.jpg\" style=\"width:80%; height:auto;\"/></center>\n",
    "Nvidia’s 4 stages\n",
    "https://medium.com/nvidia-merlin/recommender-systems-not-just-recommender-models-485c161c755e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A Recsys Other Blueprint\n",
    "<center><img src=\"img/recsys31.jpg\" style=\"width:50%; height:auto;\"/></center>\n",
    "https://eugeneyan.com/writing/system-design-for-discovery/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A Recsys Other Blueprint\n",
    "<center><img src=\"img/Netflixbp.jpg\" style=\"width:50%; height:auto;\"/></center>\n",
    "https://netflixtechblog.com/system-architectures-for-personalization-and-recommendation-e081aa94b5d8\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What are your takeaways from this session?\n",
    "\n",
    "- **There’s much more than ML to a recommender system**\n",
    "  - Aspects such as the UX, Serendipity, Diversity, Explanations, scalability, and other system concerns might matter just as much or more\n",
    "\n",
    "- **A good initial recommendation baseline for any system is simply recommending “most popular”**\n",
    "\n",
    "- **There are two main approaches to recommendations: collaborative filtering (CF) and content-based (CB)**\n",
    "  - **In CF we only use information about past user behavior to form our predictions**\n",
    "    - We can use past user actions to find similar users or items (memory-based) or train an ML model\n",
    "    - While there are many ML approaches to CF, Matrix Factorization is usually the preferred technique\n",
    "    - CF is considered the best approach to recommendations in isolation\n",
    "    - CF is agnostic to content and domain, and it is easy to implement out of the box. However, it suffers from popularity bias and cold start problems (i.e., cannot recommend content that has no/few interactions)\n",
    "  \n",
    "  - **In CB we only use information about the content itself to infer recommendations**\n",
    "    - Information from the content can be manually extracted (e.g., tags) or automatically extracting features (e.g., embeddings or automatic tagging)\n",
    "    - CB recommendations work well for new content or content in the long tail, but it is hard to inject exploration since we always recommend “similar” items.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What are your takeaways from this session?\n",
    "\n",
    "- **Different approaches to recommendations can be combined through hybridization, particularly through an ensemble**\n",
    "  - An ensemble can turn any model into the feature of a more general model\n",
    "\n",
    "- **From an architectural perspective, a recsys is composed of:**\n",
    "  - **Modeling**\n",
    "    - Sampling, feature extraction, model training, model testing, parameter tuning, model deployment\n",
    "  - **Inference/presentation**\n",
    "    - Candidate generation, feature extraction, scoring, post-processing, ranking/rendering, logging\n",
    "  - **All these processes can be done offline, nearline, or online**\n",
    "    - The earlier in the funnel a process is, the more likely it will be done offline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# \"Homework\"\n",
    "\n",
    "- **Given what you know at this point, how would you go about implementing your first recsys end to end?**\n",
    "  - You can think about a use case you know about, otherwise think about recommending daily news via email.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [],
   "name": "neural-ode.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "rise": {
   "controlsTutorial": false,
   "height": 900,
   "help": false,
   "margin": 0,
   "maxScale": 2,
   "minScale": 0.2,
   "progress": true,
   "scroll": true,
   "theme": "simple",
   "width": 1200
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
