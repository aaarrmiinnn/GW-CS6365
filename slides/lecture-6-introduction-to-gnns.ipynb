{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i_f5u2x9nn6I",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<left><img width=25% src=\"img/gw_monogram_2c.png\"></left>\n",
    "\n",
    "# Lecture 6: Introduction to Graph Neural Networks\n",
    "\n",
    "### CS4907/CS6365 Machine Learning\n",
    "\n",
    "__Sardar Hamidian__<br>The George Washington Universiry\n",
    "\n",
    "__Armin Mehrabian__<br>The George Washington Universiry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Recap: Shallow Encoders\n",
    "\n",
    "## Limitations of shallow embedding methods:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **$O(|V|)$ parameters are needed**:\n",
    "    - No sharing of parameters between nodes\n",
    "    - Every node has its own unique embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Inherently \"transductive\"**:\n",
    "    - Cannot generate embeddings for nodes that are not seen during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Do not incorporate node features**:\n",
    "    - Many graphs have features that we can and should leverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep Graph Encoders\n",
    "\n",
    "- **Today**: We will now discuss deep methods based on graph neural networks (GNNs):\n",
    "\n",
    "$$ \\text{ENC}(v) = \\text{multiple layers of non-linear transformations based on graph structure} $$\n",
    "\n",
    "- **Note**: All these deep encoders can be combined with node similarity functions defined in Lecture 4.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep Graph Encoders\n",
    "\n",
    "- **Deep graph encoders** utilize graph neural networks (GNNs) to learn node embeddings by performing multiple layers of non-linear transformations based on the graph structure.\n",
    "\n",
    "![Deep Graph Encoders Image](./img/deep_graph_encoders.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Key Advantages**:\n",
    "    - Can generalize to unseen nodes (inductive)\n",
    "    - Share parameters across the graph, reducing complexity\n",
    "    - Can incorporate node features and graph structure effectively\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Applications**:\n",
    "    - Node classification\n",
    "    - Link prediction\n",
    "    - Community Detection\n",
    "    - Graph-level tasks (e.g., molecular graph classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agenda\n",
    "# Local Network Neighborhoods\n",
    "\n",
    "- Describe aggregation strategies\n",
    "- Define computation graphs\n",
    "\n",
    "# Stacking Multiple Layers\n",
    "\n",
    "- Describe the model, parameters, and training\n",
    "- How to fit the model\n",
    "- Simple example for unsupervised and supervised training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Setup\n",
    "\n",
    "- **Assume we have a graph $G$:**\n",
    "    - $V$ is the **vertex set**\n",
    "    - $A$ is the **adjacency matrix** (assume binary)\n",
    "    - $X \\in \\mathbb{R}^{m \\times |V|}$ is a matrix of **node features**\n",
    "    - $v$: a node in $V$; $N(v)$: the set of neighbors of $v$\n",
    "\n",
    "- **Node features**:\n",
    "    - **Social networks**: User profile, User image\n",
    "    - **Biological networks**: Gene expression profiles, gene functional information\n",
    "    - **When there is no node feature in the graph dataset**:\n",
    "        - Indicator vectors (one-hot encoding of a node)\n",
    "        - Vector of constant 1: $[1, 1, 1, ..., 1]$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Na√Øve Approach\n",
    "\n",
    "- **Join adjacency matrix and features**\n",
    "- **Feed them into a deep neural net**:\n",
    "\n",
    "![Na√Øve Approach Image](./img/gnn_to_dnn.png)\n",
    "\n",
    "### Issues with this idea:\n",
    "\n",
    "- **$O(|V|)$ parameters**\n",
    "- **Not applicable to graphs of different sizes**\n",
    "- **Sensitive to node ordering**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Inspiration from CNNs\n",
    "\n",
    "![CNN Analogy](./img/cnn_analogy.png)\n",
    "\n",
    "- Goal is to generalize convolutions beyond simple lattices Leverage node features/attributes (e.g., text, images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# However in Graph World\n",
    "\n",
    "![Sliding Window in Graphs](./img/graph_sliding_window.png)\n",
    "\n",
    "- There is no fixed notion of locality or sliding window on the graph\n",
    "- Graph is permutation invariant\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# From Images to Graphs\n",
    "\n",
    "- **Single Convolutional Neural Network (CNN) layer with 3x3 filter:**\n",
    "\n",
    "![CNNs vs Graphs](./img/cnn_vs_graphs.png)\n",
    "\n",
    "### Idea: Transform information at the neighbors and combine it:\n",
    "- Transform \"messages\" $h_i$ from neighbors: $W_i h_i$\n",
    "- Add them up: $\\sum_i W_i h_i$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Graph Convolutional Networks\n",
    "\n",
    "### Idea: Node's neighborhood defines a computation graph\n",
    "\n",
    "- **Determine node computation graph** \n",
    "- **Propagate and transform information** \n",
    "![Graph Convolutional Networks Image](./img/propagate_and_aggregate.png)\n",
    "\n",
    "### Learn how to propagate information across the graph to compute node features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Idea: Aggregate Neighbors\n",
    "\n",
    "- Key idea: Generate node embeddings based on local network neighborhoods\n",
    "\n",
    "![GNN Idea 1](./img/gnn_idea_1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Intuition: Network neighborhood defines a computation graph\n",
    "- Every node defines a computa2on graph based on its neighborhood!\n",
    "\n",
    "![GNN Idea 3](./img/gnn_idea_3.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep Model: Many Layers\n",
    "\n",
    "- Model can be of arbitrary depth:\n",
    "    - Nodes have embeddings at each layer\n",
    "    - Layer-0 embedding of node $ùë£$ is its input feature, $ùë•_ùë£$\n",
    "    - Layer-ùëò embedding gets information from nodes that are $ùëò$ hops away\n",
    "    \n",
    "![GNN Idea 4](./img/gnn_idea_4.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Neighborhood Aggregation\n",
    "\n",
    "- **Neighborhood aggregation:** Key distinctions are in how different approaches aggregate information across the layers\n",
    "\n",
    "![GNN Idea 5](./img/gnn_idea_5.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neighborhood Aggregation\n",
    "\n",
    "- **Basic approach:** Average information from neighbors and apply a neural network\n",
    "\n",
    "![GNN Idea 6](./img/gnn_idea_6.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The Math: Deep Encoder\n",
    "\n",
    "- **Basic approach**: Average neighbor messages and apply a neural network\n",
    "\n",
    "$$ h_v^0 = x_v $$\n",
    "\n",
    "$$ h_v^{(l+1)} = \\sigma\\left(W_l \\sum_{u \\in N(v)} \\frac{h_u^{(l)}}{|N(v)|} + B_l h_v^{(l)}\\right), \\forall l \\in \\{0, \\dots, L-1\\} $$\n",
    "\n",
    "$$ z_v = h_v^{(L)} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neighborhood Aggregation\n",
    "\n",
    "- **Basic approach:** Average information from neighbors and apply a neural network\n",
    "\n",
    "![GNN Idea 7](./img/gnn_idea_7.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The Math: Deep Encoder\n",
    "\n",
    "\n",
    "- **Basic approach**: Average neighbor messages and apply a neural network\n",
    "\n",
    "$$ h_v^{(0)} = x_v $$\n",
    "\n",
    "$$ h_v^{(k+1)} = \\sigma\\left(W_k \\sum_{u \\in N(v)} \\frac{h_u^{(k)}}{|N(v)|} + B_k h_v^{(k)}\\right), \\forall k \\in \\{0, \\dots, K-1\\} $$\n",
    "\n",
    "$$ z_v = h_v^{(K)} $$\n",
    "\n",
    "- **$W_k$ and $B_k$** are the trainable weight matrices (i.e., what we learn).\n",
    "- **$z_v$** is the final node embedding.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Matrix Formulation (1)\n",
    "\n",
    "- **Many aggregations can be performed efficiently by (sparse) matrix operations:**\n",
    "\n",
    "$$ H^{(l)} = \\left[ h_1^{(l)} \\, \\dots \\, h_{|V|}^{(l)} \\right]^T $$\n",
    "\n",
    "- **What is $H^{(l)}$?**\n",
    "  - $H^{(l)}$ is a matrix of node embeddings at layer $l$. \n",
    "  - Each row $h_v^{(l)}$ represents the hidden embedding (or feature vector) of node $v$ at layer $l$.\n",
    "  - The dimensions of $H^{(l)}$ are $|V| \\times d$, where $|V|$ is the number of nodes and $d$ is the embedding dimension.\n",
    "  - These embeddings capture information about the node and its neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Then: \n",
    "\n",
    "$$ \\sum_{u \\in N(v)} h_u^{(l)} = A_{v,:} H^{(l)} $$\n",
    "\n",
    "- **What is $D$?**\n",
    "  - $D$ is a diagonal degree matrix where the diagonal entry $D_{v,v}$ is the degree of node $v$, i.e., $\\text{Deg}(v) = |N(v)|$.\n",
    "  - The inverse of $D$, $D^{-1}$, is also diagonal, where $D^{-1}_{v,v} = \\frac{1}{|N(v)|}$.\n",
    "  - This matrix normalizes the node embeddings by scaling contributions from neighbors based on node degree.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Therefore:**\n",
    "\n",
    "$$ \\sum_{u \\in N(v)} \\frac{h_u^{(l-1)}}{|N(v)|} \\longrightarrow H^{(l+1)} = D^{-1} A H^{(l)} $$\n",
    "\n",
    "- This formula expresses how node embeddings from neighbors are aggregated using sparse matrix multiplication with the adjacency matrix $A$ and normalized by $D^{-1}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Matrix Formulation (2)\n",
    "\n",
    "- **Re-writing the update function in matrix form:**\n",
    "\n",
    "$$ H^{(l+1)} = \\sigma\\left(\\tilde{A} H^{(l)} W_l^T + H^{(l)} B_l^T \\right) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  where:\n",
    "\n",
    "$$ \\tilde{A} = D^{-1} A $$\n",
    "\n",
    "- **Explanation**:\n",
    "  - **Neighborhood aggregation**: The term $( \\tilde{A} H^{(l)} W_l^T $) aggregates information from the neighbors using the normalized adjacency matrix $( \\tilde{A} )$.\n",
    "  - **Self-transformation**: The term $( H^{(l)} B_l^T $) applies a transformation to the node itself without aggregation from its neighbors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- **In practice**, this implies that efficient sparse matrix multiplication can be used (since $( \\tilde{A} $) is sparse).\n",
    "\n",
    "- **Note**: Not all GNNs can be expressed in matrix form, especially when the aggregation function is more complex.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How to train a GNN\n",
    "\n",
    "- **Node embedding $z_v$** is a function of the input graph.\n",
    "\n",
    "- **Supervised setting**: we want to minimize the loss $\\mathcal{L}$:\n",
    "\n",
    "$$ \\min_{\\Theta} \\mathcal{L}(y, f(z_v)) $$\n",
    "\n",
    "  - $y$: node label\n",
    "  - $\\mathcal{L}$ could be L2 if $y$ is a real number, or cross-entropy if $y$ is categorical.\n",
    "\n",
    "- **Unsupervised setting**:\n",
    "  - No node label available.\n",
    "  - Use the graph structure as the supervision!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Unsupervised Training\n",
    "\n",
    "### \"Similar\" nodes have similar embeddings\n",
    "\n",
    "$$ \\mathcal{L} = \\sum_{z_u, z_v} \\text{CE}(y_{u,v}, \\text{DEC}(z_u, z_v)) $$\n",
    "\n",
    "- Where $y_{u,v} = 1$ when node $u$ and $v$ are **similar**.\n",
    "- **CE** is the cross entropy.\n",
    "- **DEC** is the decoder, such as inner product (lecture 4).\n",
    "\n",
    "- **Node similarity** can be anything from lecture 3, e.g., a loss based on:\n",
    "  - **Random walks** (node2vec, DeepWalk, struc2vec).\n",
    "  - **Matrix factorization**.\n",
    "  - **Node proximity** in the graph.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Supervised Training\n",
    "\n",
    "- **Directly train** the model for a supervised task (e.g., **node classification**).\n",
    "- Use cross-entropy loss (slide 16):\n",
    "\n",
    "$$ \\mathcal{L} = \\sum_{v \\in V} \\left[ y_v \\log(\\sigma(z_v^T \\Theta)) + (1 - y_v) \\log(1 - \\sigma(z_v^T \\Theta)) \\right] $$\n",
    "\n",
    "- **Explanation**:\n",
    "  - $z_v$: Encoder output, i.e., the node embedding for node $v$.\n",
    "  - $y_v$: The node class label (1 if the node belongs to a certain class, 0 otherwise).\n",
    "  - $\\Theta$: Classification weights applied to the node embedding.\n",
    "  - $\\sigma$: Sigmoid function, producing the probability that the node belongs to the class.\n",
    "  \n",
    "- Example: Safe or toxic drug? The node embedding represents a drug, and the classification determines the outcome (safe/toxic).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Training Overview\n",
    "\n",
    "![GNN Design Overview 1 2](./img/gnn_design_1_2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Training Overview\n",
    "\n",
    "![GNN Design Overview 3](./img/gnn_design_3.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Training Overview\n",
    "\n",
    "![GNN Design Overview 4](./img/gnn_design_4.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The same aggregation parameters are shared for all nodes:\n",
    "- The number of model parameters is sublinear in $|ùëâ|$ and we can generalize to unseen nodes!\n",
    "\n",
    "![GNN Shared parameters](./img/gnn_shared_params.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Inductive Embedding](./img/inductive_node_embedding.png)\n",
    "\n",
    "- Inductive node embedding Generalize to entirely unseen graphs\n",
    "- E.g., train on protein interaction graph from model organism A and generate embeddings on newly collected data about organism B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Inductive Embedding](./img/dynamic_graph_node_embedding.png)\n",
    "- Many application settings constantly encounter previously unseen nodes:\n",
    "    - E.g., Reddit, YouTube, Google Scholar\n",
    "- Need to generate new embeddings on demand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Summary\n",
    "\n",
    "- **Recap**: Generate node embeddings by aggregating neighborhood information.\n",
    "  - We saw a **basic variant** of this idea.\n",
    "  - Key distinctions are in how different approaches aggregate information across the layers.\n",
    "\n",
    "- **Next**: Describe GraphSAGE graph neural network architecture.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [],
   "name": "neural-ode.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:gwu] *",
   "language": "python",
   "name": "conda-env-gwu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "rise": {
   "controlsTutorial": false,
   "height": 900,
   "help": false,
   "margin": 0,
   "maxScale": 2,
   "minScale": 0.2,
   "progress": true,
   "scroll": true,
   "theme": "simple",
   "width": 1200
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
